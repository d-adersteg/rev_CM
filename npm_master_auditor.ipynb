{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIAP to Product Mapping Audit\n",
    "This notebook automates the reconciliation between Jira initiatives, the NIAP Product Register, and Core Inventory. \n",
    "\n",
    "### How it works:\n",
    "1. **Extraction**: Pulls data from SQL databases.\n",
    "2. **Phase A**: Calculates baseline metrics for data quality.\n",
    "3. **Phase B**: Links products using three levels of matching (Direct Link, Fuzzy Register Match, and Direct Jira Match).\n",
    "4. **Reporting**: Generates summary reports and uploads results to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from rapidfuzz import process, fuzz, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "Update the `TARGET_FOLDER_ID` if you want to upload to a different Google Drive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Google Drive folder ID where artifacts will be uploaded\n",
    "TARGET_FOLDER_ID = \"15xKraT4MhWzBvOjMTJ0x21TBIopqfl4E\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# File names for exported artifacts\n",
    "CSV_JIRA = f\"raw_jira_initiatives_{TIMESTAMP}.csv\"\n",
    "CSV_REG  = f\"raw_niap_register_{TIMESTAMP}.csv\"\n",
    "CSV_CORE = f\"raw_core_inventory_{TIMESTAMP}.csv\"\n",
    "CSV_MASTER = f\"master_reconciliation_table_{TIMESTAMP}.csv\"\n",
    "JSON_METRICS = f\"data_overview_metrics_{TIMESTAMP}.json\"\n",
    "JSON_ANALYSIS = f\"mapping_metrics_analysis_{TIMESTAMP}.json\"\n",
    "REPORT_MD = f\"audit_analysis_report_{TIMESTAMP}.md\"\n",
    "TXT_METADATA = f\"audit_provenance_metadata_{TIMESTAMP}.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utilities\n",
    "Helper functions for cleaning data and handling special formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    \"\"\"Helps save NumPy numbers (from Pandas) into standard JSON format.\"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer): return int(obj)\n",
    "        if isinstance(obj, np.floating): return float(obj)\n",
    "        if isinstance(obj, np.ndarray): return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "def clean_technical_name(text):\n",
    "    \"\"\"\n",
    "    Simplifies product names for better matching by removing technical noise.\n",
    "    Example: 'PT_PRODUCT_A_GB' becomes 'product a'.\n",
    "    \"\"\"\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = str(text).upper()\n",
    "    \n",
    "    # Replace underscores with spaces to help identify individual words\n",
    "    text = text.replace('_', ' ')\n",
    "    \n",
    "    # Remove country codes (GB, US, etc.)\n",
    "    country_codes = r'GB|EUR|US|AU|NZ|SG|JP|RO|FR|PL|ES|IT|IE'\n",
    "    text = re.sub(rf'\\b({country_codes})\\b', ' ', text)\n",
    "    \n",
    "    # Remove technical prefixes/suffixes\n",
    "    identifiers = [r'PT', r'MF', r'ACQ', r'REVX', r'REPRICING', r'PLAN', r'BASE', r'STD', r'PREM', r'METAL', r'STANDARD']\n",
    "    for pattern in identifiers: \n",
    "        text = re.sub(rf'\\b{pattern}\\b', ' ', text)\n",
    "    \n",
    "    # Remove remaining non-alphanumeric characters and extra spaces\n",
    "    text = re.sub(r'[^A-Z0-9\\s]', ' ', text) \n",
    "    return \" \".join(text.split()).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fuzzy Matching Engine\n",
    "This section handles the 'fuzzy' matching logic, which allows us to find matches even if names aren't exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartMatcher:\n",
    "    \"\"\" \n",
    "    Finds the closest match for a name in a reference list.\n",
    "    Uses 'WRatio' which is robust to word re-ordering.\n",
    "    \"\"\"\n",
    "    def __init__(self, source_list):\n",
    "        # Prepare the list we are matching AGAINST\n",
    "        self.original_source = [str(x) for x in source_list if pd.notna(x)]\n",
    "        self.clean_source = [utils.default_process(x) for x in self.original_source]\n",
    "\n",
    "    def match(self, query_list, threshold=82):\n",
    "        \"\"\"Matches a list of queries against the source list.\"\"\"\n",
    "        if not query_list: return []\n",
    "        \n",
    "        # 1. Pre-process the queries to match the source format\n",
    "        processed_queries = [utils.default_process(str(q)) for q in query_list]\n",
    "        \n",
    "        # 2. Performance Optimization: Use batch processing (cdist) for large datasets (100k+ rows)\n",
    "        # This runs on all CPU cores and is much faster than a standard loop.\n",
    "        if len(query_list) > 100:\n",
    "            # Calculate all scores at once using multi-threading\n",
    "            scores = process.cdist(processed_queries, self.clean_source, scorer=fuzz.WRatio, workers=-1)\n",
    "            results = []\n",
    "            for i in range(len(query_list)):\n",
    "                if not query_list[i] or str(query_list[i]).strip() == \"\":\n",
    "                    results.append({\"best_match\": None, \"score\": 0})\n",
    "                    continue\n",
    "                best_idx = np.argmax(scores[i])\n",
    "                best_score = scores[i][best_idx]\n",
    "                if best_score >= threshold:\n",
    "                    results.append({\"best_match\": self.original_source[best_idx], \"score\": round(float(best_score), 2)})\n",
    "                else:\n",
    "                    results.append({\"best_match\": None, \"score\": 0})\n",
    "            return results\n",
    "        else:\n",
    "            # Standard matching for smaller lists\n",
    "            results = []\n",
    "            for q in processed_queries:\n",
    "                if not q:\n",
    "                    results.append({\"best_match\": None, \"score\": 0})\n",
    "                    continue\n",
    "                match = process.extractOne(q, self.clean_source, scorer=fuzz.WRatio, processor=None)\n",
    "                if match and match[1] >= threshold:\n",
    "                    results.append({\"best_match\": self.original_source[match[2]], \"score\": round(match[1], 2)})\n",
    "                else:\n",
    "                    results.append({\"best_match\": None, \"score\": 0})\n",
    "            return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reporting & Drive Logic\n",
    "Functions to summarize results and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audit_manifest(exec_time, sql_map):\n",
    "    \"\"\"Saves the exact SQL queries used for audit traceability.\"\"\"\n",
    "    content = f\"\"\"NIAP AUDIT: FORENSIC METADATA MANIFEST\n",
    "================================================================================\n",
    "EXECUTION TIMESTAMP: {exec_time}\n",
    "ALGORITHM: RapidFuzz (WRatio) | THRESHOLD: 82%\n",
    "NORMALIZATION: Stripping country codes and technical identifiers.\n",
    "\n",
    "DATA PROVENANCE (EXACT SQL EXECUTION):\n",
    "--------------------------------------------------------------------------------\n",
    "1. JIRA SOURCE:\n",
    "   {sql_map['jira']}\n",
    "\n",
    "2. REGISTER SOURCE:\n",
    "   {sql_map['reg']}\n",
    "\n",
    "3. CORE INVENTORY SOURCE:\n",
    "   {sql_map['core']}\n",
    "\n",
    "LOGIC HIERARCHY:\n",
    "--------------------------------------------------------------------------------\n",
    "1. B1 (Reg->Jira): Match Register Name to Jira Summary. Priority: Direct NIAP ID > Fuzzy Match.\n",
    "2. B2 (Core->Reg): Match Cleaned Core Name to Register Name. If found, inherit Jira Ticket.\n",
    "3. B3 (Core->Jira): Match Cleaned Core Name to Jira Summary. Only runs if B2 fails.\n",
    "\"\"\"\n",
    "    with open(TXT_METADATA, 'w') as f: f.write(content)\n",
    "\n",
    "def generate_deep_dive_report(metrics_a, metrics_b):\n",
    "    \"\"\"Generates a Markdown report summarizing the audit findings.\"\"\"\n",
    "    # 1. Jira Status Table\n",
    "    jira_table = \"| Status | Total Tickets | Linked to Reg | Coverage % |\\n|---|---|---|---|\\n\"\n",
    "    for status, data in metrics_a['a1_jira_governance']['linkage_analysis'].items():\n",
    "        jira_table += f\"| {status} | {data['total_tickets']} | {data['tickets_with_link']} | {data['coverage_pct']}% |\\n\"\n",
    "\n",
    "    # 2. Register Health Table\n",
    "    reg_table = \"| Product Status | Total Records | Populated NIAP IDs |\\n|---|---|---|\\n\"\n",
    "    for status, data in metrics_a['a2_register_health']['id_health_by_status'].items():\n",
    "        reg_table += f\"| {status} | {data['total_records']} | {data['populated_ids']} |\\n\"\n",
    "\n",
    "    # 3. Core Inventory Breakdown\n",
    "    core_table = \"| Product Type | Active Configurations |\\n|---|---|\\n\"\n",
    "    sorted_core = dict(sorted(metrics_a['a3_core_summary']['breakdown_by_type'].items(), key=lambda item: item[1], reverse=True))\n",
    "    for p_type, count in sorted_core.items():\n",
    "        core_table += f\"| {p_type} | {count} |\\n\"\n",
    "\n",
    "    # 4. Gap Analysis Table\n",
    "    gap_table = \"| Product Type | Risk Volume (Unmapped) |\\n|---|---|\\n\"\n",
    "    gap_data = metrics_b['master_summary']['gap_risk_volume_by_type']\n",
    "    for p_type, vol in gap_data.items():\n",
    "        gap_table += f\"| {p_type} | {vol} |\\n\"\n",
    "\n",
    "    md = f\"\"\"# NIAP Audit: Deep Dive Analysis Report\n",
    "**Timestamp:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\n",
    "## 1. Executive Summary\n",
    "| Metric | Value |\n",
    "|---|---|\n",
    "| **Total Product Families** | {metrics_b['master_summary']['total_families']} |\n",
    "| **Compliant Families** | {metrics_b['master_summary']['compliant']} |\n",
    "| **Gap Families** | {metrics_b['master_summary']['gaps']} |\n",
    "| **Total Risk Volume** | {metrics_a['a3_core_summary']['total_configs']} |\n",
    "\n",
    "## 2. Phase A: Source Data Health\n",
    "\n",
    "### 2.1 Jira Governance Linkage (By Status)\n",
    "{jira_table}\n",
    "\n",
    "### 2.2 Product Registry Health (By Status)\n",
    "{reg_table}\n",
    "\n",
    "### 2.3 Core Inventory Composition (Risk Profile)\n",
    "{core_table}\n",
    "\n",
    "## 3. Phase B: Mapping & Gap Analysis\n",
    "\n",
    "### 3.1 Unmapped Risk Volumes (Gaps)\n",
    "{gap_table}\n",
    "\"\"\"\n",
    "    with open(REPORT_MD, 'w') as f: f.write(md)\n",
    "\n",
    "def upload_to_drive(file_path, mime_type):\n",
    "    \"\"\"Uploads the result files to Google Drive with retries.\"\"\"\n",
    "    max_retries = 3\n",
    "    print(f\" -> Uploading {file_path}...\")\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Note: upload_file_to_gdrive must be available in the environment\n",
    "            upload_file_to_gdrive(file=file_path, name=file_path, mime_type=mime_type, folder_id=TARGET_FOLDER_ID)\n",
    "            return # Success\n",
    "        except NameError:\n",
    "            print(\"    [WARN] upload_file_to_gdrive not found. Skipping upload (Local Mode).\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"    [WARN] Attempt {attempt+1}/{max_retries} failed: {str(e)}\")\n",
    "            if attempt < max_retries - 1: \n",
    "                time.sleep(5) \n",
    "            else:\n",
    "                print(f\"    [ERROR] Failed to upload {file_path} after {max_retries} attempts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Extraction\n",
    "Connect to the database and fetch the Jira, Register, and Inventory data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\n",
    "    \"jira\": \"SELECT issue_id, summary, issue_status, product_register_link FROM global_entity_operations.jira_niap_initiatives\",\n",
    "    \"reg\": \"SELECT name, niap, product_status FROM global_entity_operations.niap_product_register\",\n",
    "    \"core\": \"SELECT product_type, name, COUNT(*) as configuration_count FROM core.products WHERE (decommission_date IS NULL OR decommission_date > CURRENT_DATE) GROUP BY 1, 2\"\n",
    "}\n",
    "\n",
    "print(f\"[{datetime.now()}] Phase A: Extraction...\")\n",
    "try:\n",
    "    # Note: zeus() and execute_sql() must be available in the environment\n",
    "    with zeus() as cur:\n",
    "        df_jira = execute_sql(cur, queries[\"jira\"], None)\n",
    "        df_reg  = execute_sql(cur, queries[\"reg\"], None)\n",
    "        df_core = execute_sql(cur, queries[\"core\"], None)\n",
    "    print(\"Successfully loaded data from SQL.\")\n",
    "except NameError:\n",
    "    print(\"    [ERROR] SQL functions (zeus/execute_sql) not found. Please run in the correct environment.\")\n",
    "except Exception as e:\n",
    "    print(f\"Extraction failed: {e}.\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Phase A: Source Health\n",
    "Calculate metrics about how much data is already linked or populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Jira stats\n",
    "df_jira['has_reg_link'] = df_jira['product_register_link'].notna() & (df_jira['product_register_link'].astype(str) != 'None')\n",
    "jira_stats = df_jira.groupby('issue_status').agg(total_tickets=('issue_id', 'count'), tickets_with_link=('has_reg_link', 'sum'))\n",
    "jira_stats['coverage_pct'] = (jira_stats['tickets_with_link'] / jira_stats['total_tickets'] * 100).round(2)\n",
    "\n",
    "# Calculate Register stats\n",
    "df_reg['niap_populated'] = df_reg['niap'].notna() & (~df_reg['niap'].astype(str).isin(['None', 'nan', '']))\n",
    "df_reg['product_status'] = df_reg['product_status'].fillna('Unknown')\n",
    "reg_health = df_reg.groupby('product_status').agg(total_records=('name', 'count'), populated_ids=('niap_populated', 'sum'))\n",
    "\n",
    "metrics_a = {\n",
    "    \"a1_jira_governance\": {\"total_initiatives\": len(df_jira), \"linkage_analysis\": jira_stats.to_dict('index')},\n",
    "    \"a2_register_health\": {\"total\": len(df_reg), \"id_health_by_status\": reg_health.to_dict('index')},\n",
    "    \"a3_core_summary\": {\n",
    "        \"total_configs\": int(df_core['configuration_count'].sum()),\n",
    "        \"breakdown_by_type\": df_core.groupby('product_type')['configuration_count'].sum().to_dict()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Phase B: Mapping Logic\n",
    "This is the core logic that connects the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.now()}] Phase B1: Register to Jira Mapping...\")\n",
    "j_matcher = SmartMatcher(df_jira['summary'].tolist())\n",
    "j_id_map = dict(zip(df_jira['summary'], df_jira['issue_id']))\n",
    "j_status_map = dict(zip(df_jira['issue_id'], df_jira['issue_status']))\n",
    "\n",
    "b1_results = {}\n",
    "b1_matches = j_matcher.match(df_reg['name'].tolist())\n",
    "\n",
    "for i, row in df_reg.iterrows():\n",
    "    name = str(row['name'])\n",
    "    # Priority 1: Use direct NIAP link if available\n",
    "    key = str(row['niap']) if pd.notna(row['niap']) else \"nan\"\n",
    "    match = b1_matches[i]\n",
    "    \n",
    "    if key in j_status_map:\n",
    "        res = {\"ticket\": key, \"method\": \"Direct Link\", \"conf\": 100}\n",
    "    elif match['best_match']:\n",
    "        res = {\"ticket\": j_id_map.get(match['best_match']), \"method\": \"Fuzzy (WRatio)\", \"conf\": match['score']}\n",
    "    else:\n",
    "        res = {\"ticket\": \"-\", \"method\": \"GAP\", \"conf\": 0}\n",
    "    b1_results[name.lower()] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.now()}] Phase B2/B3: Core Inventory Mapping...\")\n",
    "# Group inventory by name to reduce the number of matches we need to perform\n",
    "core_families = df_core.groupby(['product_type', 'name'])['configuration_count'].sum().reset_index()\n",
    "core_families['clean_name'] = core_families['name'].apply(clean_technical_name)\n",
    "\n",
    "r_matcher = SmartMatcher(df_reg['name'].tolist())\n",
    "b2_matches = r_matcher.match(core_families['clean_name'].tolist(), threshold=85)\n",
    "b3_matches = j_matcher.match(core_families['clean_name'].tolist(), threshold=85)\n",
    "\n",
    "master_results = []\n",
    "for i, c_row in core_families.iterrows():\n",
    "    ticket, path, best_reg = \"-\", \"GAP\", \"-\"\n",
    "    \n",
    "    # Priority 2: Match Core Inventory -> Register -> Jira\n",
    "    if b2_matches[i]['best_match']:\n",
    "        best_reg = b2_matches[i]['best_match']\n",
    "        link = b1_results.get(best_reg.lower())\n",
    "        if link and link['ticket'] != \"-\": \n",
    "            ticket, path = link['ticket'], f\"Inherited via Register ({link['method']})\"\n",
    "    \n",
    "    # Priority 3: Match Core Inventory -> Direct Jira (if Register match failed)\n",
    "    if ticket == \"-\" and b3_matches[i]['best_match']:\n",
    "         found_id = j_id_map.get(b3_matches[i]['best_match'])\n",
    "         if found_id: \n",
    "             ticket, path = found_id, \"Direct Match to Jira\"\n",
    "\n",
    "    master_results.append({\n",
    "        \"product_family\": c_row['name'], \n",
    "        \"product_type\": c_row['product_type'], \n",
    "        \"risk_volume\": int(c_row['configuration_count']), \n",
    "        \"mapped_reg_entry\": best_reg, \n",
    "        \"evidence_ticket\": ticket, \n",
    "        \"status\": j_status_map.get(ticket, \"N/A\"), \n",
    "        \"traceability_path\": path\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export & Finalize\n",
    "Save the data and upload it to the drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_master = pd.DataFrame(master_results)\n",
    "    df_master.to_csv(CSV_MASTER, index=False)\n",
    "\n",
    "    gap_data = df_master[df_master['evidence_ticket'] == \"-\"]\n",
    "    metrics_b = {\n",
    "        \"b1_registry_health\": b1_results,\n",
    "        \"master_summary\": {\n",
    "            \"total_families\": len(df_master), \n",
    "            \"compliant\": len(df_master) - len(gap_data), \n",
    "            \"gaps\": len(gap_data),\n",
    "            \"gap_risk_volume_by_type\": gap_data.groupby('product_type')['risk_volume'].sum().sort_values(ascending=False).to_dict()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(JSON_METRICS, 'w') as f: json.dump(metrics_a, f, indent=4, cls=NpEncoder)\n",
    "    with open(JSON_ANALYSIS, 'w') as f: json.dump(metrics_b, f, indent=4, cls=NpEncoder)\n",
    "    \n",
    "    generate_audit_manifest(str(datetime.now()), queries)\n",
    "    generate_deep_dive_report(metrics_a, metrics_b)\n",
    "\n",
    "    df_jira.to_csv(CSV_JIRA, index=False) \n",
    "    df_reg.to_csv(CSV_REG, index=False)\n",
    "    df_core.to_csv(CSV_CORE, index=False)\n",
    "\n",
    "    print(\"Artifacts generated locally. Starting upload...\")\n",
    "\n",
    "    artifacts = [\n",
    "        (CSV_MASTER, \"text/csv\"), (JSON_METRICS, \"application/json\"), \n",
    "        (JSON_ANALYSIS, \"application/json\"), (TXT_METADATA, \"text/plain\"), \n",
    "        (REPORT_MD, \"text/markdown\"), (CSV_JIRA, \"text/csv\"), \n",
    "        (CSV_REG, \"text/csv\"), (CSV_CORE, \"text/csv\")\n",
    "    ]\n",
    "    for f_path, f_mime in artifacts:\n",
    "        if os.path.exists(f_path):\n",
    "            upload_to_drive(f_path, f_mime)\n",
    "\n",
    "    print(f\"\\n\u2705 DEEP DIVE AUDIT COMPLETE. Report: {REPORT_MD}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n\u274c EXECUTION FAILED: {str(e)}\")\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
