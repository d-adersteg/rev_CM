{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO SYNC IMPROVEMENTS FROM GITHUB/JULES\n",
    "import subprocess\n",
    "\n",
    "def pull_from_github():\n",
    "    try:\n",
    "        # This brings the GitHub 'Source of Truth' into your Jove environment\n",
    "        output = subprocess.check_output([\"git\", \"pull\", \"origin\", \"main\"], stderr=subprocess.STDOUT)\n",
    "        print(f\"‚úÖ Jove is now synced with GitHub:\\n{output.decode()}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Sync failed. Make sure you've merged Jules's PR on GitHub first.\\nError: {e.output.decode()}\")\n",
    "\n",
    "pull_from_github()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
    "import PyPDF2\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "PROJECT_ID = \"revolut-dev-apps\"\n",
    "LOCATION = \"us-central1\"\n",
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "\n",
    "# Output Files\n",
    "FILE_PAYLOAD = \"cm_risk_payload.jsonl\"\n",
    "FILE_ANALYSIS = \"cm_structural_rca.jsonl\"\n",
    "FILE_PROPOSAL = \"2026_technical_analysis.md\"\n",
    "\n",
    "# Reference Docs\n",
    "POLICY_PDF = \"CM-pol.pdf\"\n",
    "SWITCHBOARD_PDF = \"CMS.pdf\"\n",
    "\n",
    "TOTAL_NARRATIVE_THRESHOLD = 25\n",
    "\n",
    "# --- 2. HELPERS ---\n",
    "def extract_pdf_text(file_path):\n",
    "    if not os.path.exists(file_path): return \"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for page in reader.pages: text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "    except: return \"\"\n",
    "\n",
    "def process_row(row, model, instruction):\n",
    "    \"\"\"\n",
    "    Process a single row with Auto-Retry logic for 429 errors.\n",
    "    \"\"\"\n",
    "    # 1. Narrative Check\n",
    "    narrative = f\"{row.get('summary', '')} {row.get('description', '')} {row.get('root_cause_details', '')}\"\n",
    "    if len(narrative) < TOTAL_NARRATIVE_THRESHOLD:\n",
    "        return None\n",
    "\n",
    "    # 2. Payload Prep\n",
    "    full_payload = {k: (str(v) if not pd.isna(v) else \"\") for k, v in row.items()}\n",
    "    row_id = full_payload.get('id', 'unknown')\n",
    "\n",
    "    # 3. AI Analysis with Retry Backoff\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(\n",
    "                [instruction, json.dumps(full_payload)],\n",
    "                generation_config=GenerationConfig(response_mime_type=\"application/json\", temperature=0.0)\n",
    "            )\n",
    "            res = json.loads(response.text)\n",
    "\n",
    "            record = {\n",
    "                \"id\": str(row_id),\n",
    "                \"meta\": {\n",
    "                    \"dept\": str(full_payload.get('responsible_department', '')),\n",
    "                    \"severity\": str(full_payload.get('severity', '')),\n",
    "                    \"impacted\": str(full_payload.get('impacted_entities', ''))\n",
    "                },\n",
    "                \"analysis\": res\n",
    "            }\n",
    "            return (full_payload, record)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            if \"429\" in error_str or \"Resource exhausted\" in error_str:\n",
    "                if attempt < max_retries - 1:\n",
    "                    sleep_time = (2 ** attempt) + random.uniform(0, 1) # Exponential backoff\n",
    "                    print(f\" -> ‚ö†Ô∏è 429 on {row_id}, retrying in {sleep_time:.1f}s...\")\n",
    "                    time.sleep(sleep_time)\n",
    "                    continue\n",
    "            \n",
    "            # If not 429, or out of retries, log and fail\n",
    "            print(f\" -> ‚ùå Error {row_id}: {e}\")\n",
    "            return None\n",
    "\n",
    "# --- 3. SYSTEM INSTRUCTIONS ---\n",
    "\n",
    "RCA_INSTRUCTION = \"\"\"\n",
    "Analyze the incident using the full metadata.\n",
    "RETURN JSON ONLY:\n",
    "{\n",
    "  \"failure_mode\": \"[Validation Oversight | Tooling/Automation Failure | Human Error | Process Complexity | Legacy/Backward Compatibility | Guidance Gap]\",\n",
    "  \"technical_root_cause\": \"A concise, technical 5-Why summary.\",\n",
    "  \"policy_gap_classification\": \"Classify using this strict logic:\n",
    "   - IGNORED: A mandate exists in the Policy/Playbook (even high-level), but was not executed (e.g., 'Local variations must be documented' was skipped).\n",
    "   - INSUFFICIENT: The policy was followed, but the incident still occurred because the rule was too vague (e.g., 'Risk Assessment' exists but doesn't mention 'Feature Flags').\n",
    "   - MISSING: No rule exists for this domain at all.\",\n",
    "  \"policy_gap_logic\": \"Explain the gap. If IGNORED, mention what requirement was missed.\",\n",
    "  \"preventative_control\": \"Specific technical or procedural control to prevent recurrence.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "SYNTHESIS_INSTRUCTION = \"\"\"\n",
    "Perform a Technical Risk Audit of the aggregated RCA data against the provided Policy Library.\n",
    "\n",
    "OUTPUT FORMAT: Strict Technical Report (Markdown). No conversational text.\n",
    "\n",
    "REQUIRED SECTIONS:\n",
    "1. PARETO ANALYSIS: Top 2 Failure Modes by frequency & risk.\n",
    "2. COMPLIANCE AUDIT: Table of [ID | Failure Mode | Gap Type | Policy Reference].\n",
    "   - If IGNORED: Cite the specific Policy/Switchboard section violated.\n",
    "   - If INSUFFICIENT: Explain the specific deficiency in the current text.\n",
    "3. SWITCHBOARD LOGIC GAPS: Identify specific criteria in the Switchboard that are failing.\n",
    "4. DOCUMENT REDLINES: Proposed text amendments (\"Current Text\" -> \"Proposed Text\").\n",
    "\"\"\"\n",
    "\n",
    "# --- 4. SQL QUERY ---\n",
    "RCA_QUERY = \"\"\"\n",
    "SELECT\n",
    "    id, report_id, summary, description, root_cause_details,\n",
    "    responsible_department, assignee_entity, impacted_entities,\n",
    "    operating_type, brm_department_type, risk_type_id,\n",
    "    additional_risk_type_ids, cause_category_l1, cause_category_l2,\n",
    "    cause_category_l3, severity, impact_customer, impact_regulator,\n",
    "    issue_state, issue_state_category, reporting_date\n",
    "FROM risk.risk_issues\n",
    "WHERE (risk_type_id = 186 OR additional_risk_type_ids LIKE '%186%')\n",
    "AND issue_state NOT IN ('invalid', 'deleted')\n",
    "AND reporting_date >= TIMESTAMP '2024-01-01 00:00:00 UTC'\n",
    "ORDER BY reporting_date DESC\n",
    "\"\"\"\n",
    "\n",
    "def run_production_pipeline():\n",
    "    print(f\"üöÄ Starting Production Pipeline ({LOCATION})...\")\n",
    "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "    model = GenerativeModel(MODEL_NAME)\n",
    "\n",
    "    # A. DATA EXTRACTION\n",
    "    print(\"Step 1: Extracting Full Dataset...\")\n",
    "    try:\n",
    "        with zeus() as cur: df = execute_sql(cur, RCA_QUERY, None)\n",
    "        print(f\" -> Records found: {len(df)}\")\n",
    "    except Exception as e: print(f\"ERROR: {e}\"); return\n",
    "\n",
    "    # B. STRUCTURAL ANALYSIS (SAFE PARALLEL)\n",
    "    print(f\"Step 2: Processing RCAs (Max Workers=5)...\")\n",
    "    analysis_results = []\n",
    "    records = df.to_dict('records')\n",
    "\n",
    "    with open(FILE_PAYLOAD, 'w') as f_pay, open(FILE_ANALYSIS, 'w') as f_ana:\n",
    "        # Reduced workers to 5 to stay under quota\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            results = executor.map(lambda r: process_row(r, model, RCA_INSTRUCTION), records)\n",
    "\n",
    "            count = 0\n",
    "            for res in results:\n",
    "                if res:\n",
    "                    payload, record = res\n",
    "                    f_pay.write(json.dumps(payload) + '\\n')\n",
    "                    f_ana.write(json.dumps(record) + '\\n')\n",
    "                    analysis_results.append(record)\n",
    "                    \n",
    "                    count += 1\n",
    "                    if count % 20 == 0:\n",
    "                        print(f\" -> Processed {count}/{len(df)}...\")\n",
    "\n",
    "    # C. TECHNICAL SYNTHESIS\n",
    "    print(\"Step 3: Generating Technical Report...\")\n",
    "    policy_text = extract_pdf_text(POLICY_PDF)\n",
    "    switchboard_text = extract_pdf_text(SWITCHBOARD_PDF)\n",
    "\n",
    "    synthesis_payload = f\"\"\"\n",
    "    {SYNTHESIS_INSTRUCTION}\n",
    "    \n",
    "    --- REFERENCE LIBRARY ---\n",
    "    [POLICY v1.3]: {policy_text[:50000]} \n",
    "    [SWITCHBOARD]: {switchboard_text[:30000]}\n",
    "    \n",
    "    --- RCA DATASET ---\n",
    "    {json.dumps(analysis_results)}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        final_report = model.generate_content(\n",
    "            synthesis_payload,\n",
    "            generation_config=GenerationConfig(temperature=0.1)\n",
    "        )\n",
    "        with open(FILE_PROPOSAL, 'w') as f_rep:\n",
    "            f_rep.write(final_report.text)\n",
    "\n",
    "    except Exception as e: print(f\"Synthesis Error: {e}\")\n",
    "\n",
    "    # D. VERIFICATION\n",
    "    print(\"\\n‚úÖ PIPELINE COMPLETE. OUTPUT FILES:\")\n",
    "    for fname in [FILE_PAYLOAD, FILE_ANALYSIS, FILE_PROPOSAL]:\n",
    "        if os.path.exists(fname):\n",
    "            size = os.path.getsize(fname)\n",
    "            print(f\"  [CREATED] {fname:<30} Size: {size/1024:.1f} KB\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_production_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
